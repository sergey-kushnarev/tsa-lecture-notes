{
  "hash": "c2e5a4c37ff370f7b6f00b9c843770b6",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Regression Methods in Time Series Analysis\"\nauthor: \"Dr Sergey Kushnarev\"\n#date: \"March 3, 2023\"\nformat:\n  html:\n    toc: true\n    number-sections: true\n    code-fold: true\n---\n\n\n\n\n# Data Examples\n\n1. Random Walk\n2. US Population: Quadratic Trend\n3. Seasonal Means\n4. Residual Analysis\n5. Assessing Normality\n6. The Sample Autocorrelation Function\n7. Quantile-Quantile Plot of Los Angeles Annual Rainfall Series\n\n\n# Regression Methods in Time Series Analysis\n\nBased on Chapter 3, Cryer and Chan\n\nTime series are often decomposed into components: \ndeterministic and stochastic. The decomposition is additive:\n$$\nY_t = \\mu_t + X_t\n$$\nwhere $Y_t$ is the observed value at time $t$, $\\mu_t$ is the deterministic component, and $X_t$ is the stochastic component.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(TSA)\n```\n:::\n\n\n\n\n\n## Linear and Quadratic Trends in Time Series\n\n### Random Walk: apparent linear trend\n\nWe are going to fit a linear trend to a random walk\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Set seed for reproducibility\nset.seed(439)\n# Generate a random walk\nrw <- cumsum(rnorm(60))\n# Fit a linear trend to the random walk\nmodel1 <- lm(rw ~ time(rw))\n# Print the summary of the model\nsummary(model1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = rw ~ time(rw))\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-5.101 -2.414  1.064  1.970  4.063 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) -0.50344    0.70526  -0.714    0.478    \ntime(rw)     0.14957    0.02011   7.438 5.37e-10 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.697 on 58 degrees of freedom\nMultiple R-squared:  0.4882,\tAdjusted R-squared:  0.4794 \nF-statistic: 55.33 on 1 and 58 DF,  p-value: 5.371e-10\n```\n\n\n:::\n\n```{.r .cell-code}\n# Plot the random walk\nplot(rw,\n     type='o',\n     ylab='y',\n     xlab='Time',\n     main='Random Walk',\n     col='blue',\n     pch=20,\n     cex=0.5)\nabline(model1) # add the fitted least squares line from model1\nlegend('topleft',\n       legend=c('Fitted Trend Line','Random Walk'),\n       col=c('black','blue'),\n       lty=1)\n```\n\n::: {.cell-output-display}\n![](TSA-Lecture08-regression-methods_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n:::\n\n\n\n\n### US population: quadratic trend\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load the US population data\ndata(\"uspop\")\n# Fit a quadratic trend to the US population data\nmodel.pop <- lm(uspop~time(uspop)+I(time(uspop)^2)) \n# Extract the coefficients\ncoef <- model.pop$coefficients\n# Print the summary of the model\nsummary(model.pop)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = uspop ~ time(uspop) + I(time(uspop)^2))\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-6.5997 -0.7105  0.2669  1.4065  3.9879 \n\nCoefficients:\n                   Estimate Std. Error t value Pr(>|t|)    \n(Intercept)       2.045e+04  8.431e+02   24.25 4.81e-14 ***\ntime(uspop)      -2.278e+01  8.974e-01  -25.38 2.36e-14 ***\nI(time(uspop)^2)  6.345e-03  2.387e-04   26.58 1.14e-14 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.78 on 16 degrees of freedom\nMultiple R-squared:  0.9983,\tAdjusted R-squared:  0.9981 \nF-statistic:  4645 on 2 and 16 DF,  p-value: < 2.2e-16\n```\n\n\n:::\n\n```{.r .cell-code}\n# Plot the US population data\nplot(y=uspop,\n     x=as.vector(time(uspop)),\n     xlab='Time',\n     ylab='US population 1790-1970',\n     type='o',\n     col = 'blue',\n     main='US Population 1790-1970')\n# Add the fitted quadratic trend line\nlines(x=as.vector(time(uspop)),\n      y=coef[1]+coef[2]*as.vector(time(uspop))+coef[3]*as.vector(time(uspop))^2,\n      col='red')\n\n# Add the legend\nlegend('topleft',\n       legend=c('Fitted Quadratic Trend Line','US Population'),\n       col=c('red','blue'),\n       lty=1)\n```\n\n::: {.cell-output-display}\n![](TSA-Lecture08-regression-methods_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n\n\n\n\n### Seasonal (or Cyclical) Means\n\n$$\nY_t = \\mu_{t} + X_t\n$$\nHere, $\\mu_{t}$ is the seasonal mean and $X_t$ is the seasonal deviation.\n\n$$\n\\mu_1 = \\text{mean for January}, \\mu_2 = \\text{mean for February}, \\ldots, \\mu_{12} = \\text{mean for December}\n$$\n\n\nDataset: Average monthly temperatures, Dubuque, Iowa.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata(\"tempdub\")\nplot(tempdub,\n     ylab='Temperature',\n     type='o',\n     xlab='Time',\n     main='Average Monthly Temperatures, Dubuque, Iowa')\n```\n\n::: {.cell-output-display}\n![](TSA-Lecture08-regression-methods_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n:::\n\n\n\n\n### Fitting a seasonal means model (without intercept)\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmonth. <- season(tempdub) # period added to improve table display\nmodel2 <- lm(tempdub ~ month. + 0) # 0 removes the intercept term\n#model2 <- lm(tempdub ~ month. - 1) # -1 also removes the intercept term\nsummary(model2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = tempdub ~ month. + 0)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-8.2750 -2.2479  0.1125  1.8896  9.8250 \n\nCoefficients:\n                Estimate Std. Error t value Pr(>|t|)    \nmonth.January     16.608      0.987   16.83   <2e-16 ***\nmonth.February    20.650      0.987   20.92   <2e-16 ***\nmonth.March       32.475      0.987   32.90   <2e-16 ***\nmonth.April       46.525      0.987   47.14   <2e-16 ***\nmonth.May         58.092      0.987   58.86   <2e-16 ***\nmonth.June        67.500      0.987   68.39   <2e-16 ***\nmonth.July        71.717      0.987   72.66   <2e-16 ***\nmonth.August      69.333      0.987   70.25   <2e-16 ***\nmonth.September   61.025      0.987   61.83   <2e-16 ***\nmonth.October     50.975      0.987   51.65   <2e-16 ***\nmonth.November    36.650      0.987   37.13   <2e-16 ***\nmonth.December    23.642      0.987   23.95   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 3.419 on 132 degrees of freedom\nMultiple R-squared:  0.9957,\tAdjusted R-squared:  0.9953 \nF-statistic:  2569 on 12 and 132 DF,  p-value: < 2.2e-16\n```\n\n\n:::\n\n```{.r .cell-code}\nplot(tempdub,\n     ylab='Temperature',\n     type='o',\n     xlab='Time',\n     main='Average Monthly Temperatures, Dubuque, Iowa')\npoints(time(tempdub),fitted(model2), col = \"red\", type='o')\n```\n\n::: {.cell-output-display}\n![](TSA-Lecture08-regression-methods_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n\n\n\nAbove, we have\n$$\n\\mu_{t} = \\beta_{t}\n$$\n\n### With the intercept term\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel3 <- lm(tempdub ~ month.) # January is dropped automatically\nsummary(model3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = tempdub ~ month.)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-8.2750 -2.2479  0.1125  1.8896  9.8250 \n\nCoefficients:\n                Estimate Std. Error t value Pr(>|t|)    \n(Intercept)       16.608      0.987  16.828  < 2e-16 ***\nmonth.February     4.042      1.396   2.896  0.00443 ** \nmonth.March       15.867      1.396  11.368  < 2e-16 ***\nmonth.April       29.917      1.396  21.434  < 2e-16 ***\nmonth.May         41.483      1.396  29.721  < 2e-16 ***\nmonth.June        50.892      1.396  36.461  < 2e-16 ***\nmonth.July        55.108      1.396  39.482  < 2e-16 ***\nmonth.August      52.725      1.396  37.775  < 2e-16 ***\nmonth.September   44.417      1.396  31.822  < 2e-16 ***\nmonth.October     34.367      1.396  24.622  < 2e-16 ***\nmonth.November    20.042      1.396  14.359  < 2e-16 ***\nmonth.December     7.033      1.396   5.039 1.51e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 3.419 on 132 degrees of freedom\nMultiple R-squared:  0.9712,\tAdjusted R-squared:  0.9688 \nF-statistic: 405.1 on 11 and 132 DF,  p-value: < 2.2e-16\n```\n\n\n:::\n:::\n\n\n\n\nWhen we fit with the intercept term, we have\n$$\n\\mu_1 = \\beta_0,\\qquad \\mu_{t} = \\beta_0 + \\beta_{t}, \\quad t=2,3,\\ldots,12\n$$\n\n### Fitting a seasonal means model with a cosine trend\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Fitting a cosine trend model\nhar. <- harmonic(tempdub,1)\nmodel4 <- lm(tempdub ~ har.)\nsummary(model4)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = tempdub ~ har.)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-11.1580  -2.2756  -0.1457   2.3754  11.2671 \n\nCoefficients:\n                Estimate Std. Error t value Pr(>|t|)    \n(Intercept)      46.2660     0.3088 149.816  < 2e-16 ***\nhar.cos(2*pi*t) -26.7079     0.4367 -61.154  < 2e-16 ***\nhar.sin(2*pi*t)  -2.1697     0.4367  -4.968 1.93e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 3.706 on 141 degrees of freedom\nMultiple R-squared:  0.9639,\tAdjusted R-squared:  0.9634 \nF-statistic:  1882 on 2 and 141 DF,  p-value: < 2.2e-16\n```\n\n\n:::\n\n```{.r .cell-code}\n# Plot the data and the fitted cosine trend\nplot(tempdub,\n     ylab='Temperature',\n     type='o',\n     xlab='Time',\n     main='Average Monthly Temperatures, Dubuque, Iowa')\npoints(time(tempdub),fitted(model4),col='red', type='o')\n```\n\n::: {.cell-output-display}\n![](TSA-Lecture08-regression-methods_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n:::\n\n\n\n\n## Residual Analysis\n\nAfter estimating the trend by $\\hat\\mu_t$, we can predict the unobserved values \nof the stochastic component $X_t$ by $\\hat{X}_t = Y_t - \\hat{\\mu}_t$.\n\n### Seasonal model without the intercept term\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(y=rstudent(model2),\n     x=as.vector(time(tempdub)),\n     xlab='Time',\n     ylab='Standardized Residuals',\n     type='o',\n     main = 'Residuals from Seasonal Means Model w/o Intercept')\n```\n\n::: {.cell-output-display}\n![](TSA-Lecture08-regression-methods_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n\n```{.r .cell-code}\nplot(y=rstudent(model3),\n     x=as.vector(time(tempdub)),\n     xlab='Time',\n     ylab='Standardized Residuals',\n     type='l',\n     main = 'Residuals from Seasonal Means Model')\n\npoints(y=rstudent(model3),\n       x=as.vector(time(tempdub)),\n       pch=as.vector(season(tempdub)),\n       col = 1:4)\n```\n\n::: {.cell-output-display}\n![](TSA-Lecture08-regression-methods_files/figure-html/unnamed-chunk-8-2.png){width=672}\n:::\n:::\n\n\n\n\n### Residuals versus Fitted Values from Seasonal Means Model\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(y=rstudent(model3),\n     x=as.vector(fitted(model3)),\n     xlab='Fitted Trend Values',\n     ylab='Standardized Residuals',type='n',\n     main='Residuals vs Fitted Values from Seasonal Means Model')\n     points(y=rstudent(model3),\n     x=as.vector(fitted(model3)),\n     pch=as.vector(season(tempdub)), \n     col = 1:4)\n```\n\n::: {.cell-output-display}\n![](TSA-Lecture08-regression-methods_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(y=rstudent(model4),\n     x=as.vector(fitted(model4)),\n     xlab='Fitted Trend Values',\n     ylab='Standardized Residuals',type='n',\n     main='Residuals vs Fitted Values from Cosine Trends')\n     points(y=rstudent(model4),\n     x=as.vector(fitted(model4)),\n     pch=as.vector(season(tempdub)), \n     col = 1:4)\n```\n\n::: {.cell-output-display}\n![](TSA-Lecture08-regression-methods_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n:::\n\n\n\n\n\n### Assessing normality\n\nHistogram is a very rough tool to assess normality\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhist(rstudent(model3),\n     xlab='Standardized Residuals',\n     main='Histogram of Residuals from Seasonal Means Model')\n```\n\n::: {.cell-output-display}\n![](TSA-Lecture08-regression-methods_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n:::\n\n\n\n\nQQ-plot is a much better tool:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Plotting the QQ-plot\nqqnorm(rstudent(model3),\n       main='QQ-plot of Residuals from Seasonal Means Model')\nqqline(rstudent(model3),col='red',lty=2)\n```\n\n::: {.cell-output-display}\n![](TSA-Lecture08-regression-methods_files/figure-html/unnamed-chunk-12-1.png){width=672}\n:::\n:::\n\n\n\n\nQQ-plot is an excellent visual diagnostic. We can use a Shapiro-Wilk test to assess normality:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Shapiro-Wilk test for normality. H0: data is normally distributed\nshapiro.test(rstudent(model3))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tShapiro-Wilk normality test\n\ndata:  rstudent(model3)\nW = 0.9929, p-value = 0.6954\n```\n\n\n:::\n:::\n\n\n\n\nTest for independence: runs test\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Runs test for independence. H0: data is independent\nruns(rstudent(model3))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n$pvalue\n[1] 0.216\n\n$observed.runs\n[1] 65\n\n$expected.runs\n[1] 72.875\n\n$n1\n[1] 69\n\n$n2\n[1] 75\n\n$k\n[1] 0\n```\n\n\n:::\n:::\n\n\n\n\n## The Sample Autocorrelation Function\n\nAnother tool for assessing dependency is a **sample ACF**.\n\nSample autocorrelation function, for $k=1, 2, 3,\\ldots$:\n\n$$\nr_k=\\dfrac{\\sum_{t=k+1}^n(Y_t-\\bar{Y})(Y_{t-k}-\\bar{Y})}{\\sum_{t=1}^n(Y_t-\\bar{Y})^2}\n$$\n\n### Plot of Sample ACF of residuals for seasonal means model versus $k$ (*correlogram*)\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nacf(rstudent(model3),\n    main='ACF of Residuals from Seasonal Means Model')\n```\n\n::: {.cell-output-display}\n![](TSA-Lecture08-regression-methods_files/figure-html/unnamed-chunk-15-1.png){width=672}\n:::\n:::\n\n\n\n\n### Sample ACF for residuals of a linear fit to a random walk\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(y=rstudent(model1),\n     x=as.vector(time(rw)),\n     ylab='Standardized Residuals',\n     xlab='Time',\n     type='o',\n     main='Residuals from Straight Line Fit to Random Walk')\n```\n\n::: {.cell-output-display}\n![](TSA-Lecture08-regression-methods_files/figure-html/unnamed-chunk-16-1.png){width=672}\n:::\n:::\n\n\n\n\nResiduals versus Fitted Values from Straight Line Fit: larger values of residuals correspond to larger fitted values.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(y=rstudent(model1),\n     x=fitted(model1),\n     ylab='Standardized Residuals',\n     xlab='Fitted Trend Line Values',\n     type='p')\n```\n\n::: {.cell-output-display}\n![](TSA-Lecture08-regression-methods_files/figure-html/unnamed-chunk-17-1.png){width=672}\n:::\n:::\n\n\n\n\nSample Autocorrelation of Residuals from the Straight Line\nfit to the random walk\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nacf(rstudent(model1),\n    main='ACF of Residuals from Straight Line Fit to Random Walk')\n```\n\n::: {.cell-output-display}\n![](TSA-Lecture08-regression-methods_files/figure-html/unnamed-chunk-18-1.png){width=672}\n:::\n:::\n\n\n\n\nWhat if we try completely different approach to the random walk data. Let's difference the data instead and plot the sample ACF of the differenced data?\n\n$$\n\\nabla Y_t = Y_t-Y_{t-1}\n$$\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nacf(diff(rw),\n    main='ACF of Differenced Random Walk')\n```\n\n::: {.cell-output-display}\n![](TSA-Lecture08-regression-methods_files/figure-html/unnamed-chunk-19-1.png){width=672}\n:::\n:::\n\n\n\n\n### Quantile-Quantile Plot of Los Angeles Annual Rainfall Series\n\nTurns out it's an iid noise: \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata(\"larain\")\nacf(larain,\n    main='ACF of Los Angeles Annual Rainfall Series')\n```\n\n::: {.cell-output-display}\n![](TSA-Lecture08-regression-methods_files/figure-html/unnamed-chunk-20-1.png){width=672}\n:::\n:::\n\n\n\n\nIs it normal? Let's check the QQ-plot:\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nqqnorm(larain,\n       main='QQ-plot of Los Angeles Annual Rainfall Series') \nqqline(larain)\n```\n\n::: {.cell-output-display}\n![](TSA-Lecture08-regression-methods_files/figure-html/unnamed-chunk-21-1.png){width=672}\n:::\n:::\n\n\n\n\n**Q: is it left-skewed or right-skewed?**\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Shapiro Wilk test\nshapiro.test(larain)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tShapiro-Wilk normality test\n\ndata:  larain\nW = 0.94617, p-value = 0.0001614\n```\n\n\n:::\n:::\n\n\n\n\nIf we log-transform the data, we can see that it becomes more symmetric:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nqqnorm(log(larain),\n       main='QQ-plot of log-transformed Los Angeles Annual Rainfall Series') \nqqline(log(larain))\n```\n\n::: {.cell-output-display}\n![](TSA-Lecture08-regression-methods_files/figure-html/unnamed-chunk-23-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Shapiro Wilk test\nshapiro.test(log(larain))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tShapiro-Wilk normality test\n\ndata:  log(larain)\nW = 0.98742, p-value = 0.3643\n```\n\n\n:::\n:::\n",
    "supporting": [
      "TSA-Lecture08-regression-methods_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}